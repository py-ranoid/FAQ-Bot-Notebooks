{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact Retreival Bot using IDFT\n",
    "### Steps\n",
    "- Loading and preprocessing Questions and Answers from dataset\n",
    "- Setting Stopwords\n",
    "- Intitialising and training TF_IDF vectors\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                   # To load and process dataset\n",
    "import numpy as np                    # For matrix operations\n",
    "from nltk.corpus import stopwords     # Using NLTK to load stopwords\n",
    "from nltk import wordpunct_tokenize   # Using NLTK to token sentences\n",
    "\n",
    "from beakerx import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.set_option('display.width',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing Questions and Answers from dataset\n",
    "- `hdfc.pkl` : Collection of 1341 QnA about HDFC. (Scraped from HDFC's FAQ site)\n",
    "- Dropping stopwords\n",
    "- Stripping Questions of extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('hdfc.xlsx')\n",
    "df = df.drop_duplicates('Question')\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac72f20ebbd491b8d35bf546f014418",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit = 1000\n",
    "reduced = df[['Question','Answer']][:limit]\n",
    "\n",
    "qlabels = reduced['Question'].to_dict()\n",
    "alabels = reduced['Answer'].to_dict()\n",
    "\n",
    "reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting stopwords\n",
    "- Import set of common stopwords from nltk\n",
    "- Adding domain-related stopword\n",
    "- Removing question words (To distinguish between intents of questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = {'hdfc'}\n",
    "minus = {'what','how','where','when','why'}\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "stop.update(plus)\n",
    "stop.difference_update(minus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intitialising and training TF-IDF vectors\n",
    "- Setting stopwords to `stop`\n",
    "- `tf_vect` : `TfidfVectorizer` object. Can be used to convert strings to tf-idf vectors\n",
    "- `all_qs_vectors` : Matrix of TF-IDF vectors corresponding to questions in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc65f9c1c1f246f892c3ba9f3e0b2470",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_vect =TfidfVectorizer(stop_words=stop,\n",
    "                         lowercase=True,\n",
    "                         use_idf=True)\n",
    "all_qs_vectors = tf_vect.fit_transform(reduced['Question'])\n",
    "TableDisplay({\"Shape of all_qs_vectors :\":(all_qs_vectors.shape),\"Number of questions : \":all_qs_vectors.shape[0],\"Vocabulary size : \":all_qs_vectors.shape[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming context with tfidf\n",
    "context = 'How can I repay my Personal Loan?'\n",
    "context_vector = tf_vect.transform([context])\n",
    "context_matrix = context_vector.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253ae328ead941af843b8e4e5225c2a0",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying TF_IDF results\n",
    "def tabulate_vector(context):\n",
    "    values = []\n",
    "    for w in word_tokenize(context.strip()):\n",
    "        ind = tf_vect.vocabulary_.get(w.lower(),\"-\")\n",
    "        val = context_matrix[0,ind] if not ind == \"-\" else 0\n",
    "        values.append({\"Word\":w,\"Vocabulary Index\":str(ind),\"TF-IDF Value\":val})\n",
    "    TableDisplay(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Predicting closest question\n",
    "- `predict` has the following arguments\n",
    "    - `n`       : int  | Number of results (from top)\n",
    "    - `answers` : bool | Return answers or not\n",
    "    - `ret_best`: bool | Returns index of closest match\n",
    "- Steps for prediction\n",
    "    - Convert query to tfidf vector\n",
    "    - Get dot product of query vectors with each question to measures similarity\n",
    "    - Sort array indices by descending order of array values\n",
    "    - Return top n results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,n=5,answers=False,ret_indices=False):\n",
    "    # Comparing context with all questions using dot product\n",
    "    query_vector = tf_vect.transform([query])\n",
    "    sim = np.dot(all_qs_vectors, query_vector.T)\n",
    "    # Converting numpy matrix to 1D array with 146 dot products (146 questions vs context)\n",
    "    arr = sim.toarray().flatten()\n",
    "    matches = arr.argsort(axis=0)[::-1]\n",
    "    top_n_matches = matches[:n]\n",
    "    results = []\n",
    "    if ret_indices:\n",
    "        return top_n_matches\n",
    "    for i in top_n_matches:\n",
    "        res = {\"Question\":qlabels[i],\"Ans\":alabels[i]} if answers else {\"Question\":qlabels[i],\"Score\":arr[i]}\n",
    "        results.append(res)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117d593e6bd74b50a19aca09cb51c100",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict('How do I pay my personal loan ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding closest question by jaccard_distance\n",
    "- `tokens` is a dictionary mapping a question's index to a list of tokens in the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating tokens after converting to lowercase, removing stopwords and non-alphanumberic tokens\n",
    "# Note : nltk.word_tokenize does not split PIN/Pattern'\n",
    "tokens = {}\n",
    "for i in qlabels:\n",
    "    tokens[i] = set([x for x in wordpunct_tokenize(qlabels[i].lower()) if x.isalnum() and x not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating questions which have a jaccard_distance > 0.9 with another questions\n",
    "def get_jaccard_similarity(words,words2):\n",
    "    inter = words.intersection(words2)\n",
    "    union = words.union(words2)\n",
    "    return float(len(inter))/len(union),len(inter)\n",
    "\n",
    "def pred_jaccard(query,n=5):\n",
    "    words = set([x for x in wordpunct_tokenize(query.lower()) if x.isalnum() and x not in stop])\n",
    "    max_sim = -1\n",
    "    max_ind = None\n",
    "    scores = {}\n",
    "    for i in qlabels:        \n",
    "        sc = get_jaccard_similarity(words,tokens[i])\n",
    "        scores[i] = {\"question\":qlabels[i],\"score\":sc[0],\"inter\":sc[1]}\n",
    "    return pd.DataFrame(scores).T.sort_values('score',ascending=False)[:n]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard-similarity-based matching vs. TF-IDF-based matching\n",
    "- Jaccard does not depend on the rest of the corpus/questions while computing similiarity and thus treats all terms/tokens equally\n",
    "- IDF, which is used to measure the importance of the word, gives more importance to words that rarely occur in a document\n",
    "<br><br>\n",
    "\n",
    "#### Consider the question : **How does amortization work ?**\n",
    "- Jaccard suggests '*How does it work*' by matching the words **how** and **work**\n",
    "- TFIDF suggests '*How does amortization work ?*' by matching the words **amortization** since it is a less-frequent term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0828aa32ae4d58bb45f966e004e05a",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_jaccard('How does amortization work ?',5)\n",
    "# Jaccard suggests 'How does it work' by matching the words how and work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580fec4fb55042678bf84f9b5ae3185e",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict('How does amortization work ?',5)\n",
    "# TFIDF suggests 'How does amortization work ?' by matching the words amortization since it is a less-frequent term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386b7450852b48be953b8c5a1562e6bc",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency Distribution of words\n",
    "all_ = {}\n",
    "for x in list(tokens.values()):\n",
    "    for w in list(x):\n",
    "        all_[w] = all_.get(w,0)+1\n",
    "TableDisplay(all_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
